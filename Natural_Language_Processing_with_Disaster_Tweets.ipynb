{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T01:11:20.235378Z",
     "start_time": "2024-04-20T01:11:19.827037Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "7hXdmzH2Dh6D"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eog_wmH3Dh6D"
   },
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07Bw9CxBDh6G"
   },
   "source": [
    "* **Note** we note that keyword is not a real good classifier to obtain our target, and also we note that location can be an important feature to add with the text to predict our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1DVPQFlDh6G"
   },
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "### Missing keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>keyword_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>evacuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>evacuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>smoke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>collapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>collided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>Razed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target keyword_prep  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1       Reason  \n",
       "1                Forest fire near La Ronge Sask. Canada       1         fire  \n",
       "2     All residents asked to 'shelter in place' are ...       1   evacuation  \n",
       "3     13,000 people receive #wildfires evacuation or...       1   evacuation  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1        smoke  \n",
       "...                                                 ...     ...          ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1     collapse  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1            .  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1       Hawaii  \n",
       "7611  Police investigating after an e-bike collided ...       1     collided  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1        Razed  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib \n",
    "import preprocess.keywords as kw\n",
    "importlib.reload(kw)\n",
    "layer=kw.PreprocessKeywords()\n",
    "layer.preprocess(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T00:53:56.860052Z",
     "start_time": "2024-04-20T00:53:56.825983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>10826</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>TN</td>\n",
       "      <td>On the bright side I wrecked http://t.co/uEa0t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#NewcastleuponTyne #UK</td>\n",
       "      <td>@widda16 ... He's gone. You can relax. I thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>London</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                       location  \\\n",
       "31       48   ablaze                     Birmingham   \n",
       "32       49   ablaze  Est. September 2012 - Bristol   \n",
       "33       50   ablaze                         AFRICA   \n",
       "34       52   ablaze               Philadelphia, PA   \n",
       "35       53   ablaze                     London, UK   \n",
       "...     ...      ...                            ...   \n",
       "7575  10826  wrecked                             TN   \n",
       "7577  10829  wrecked         #NewcastleuponTyne #UK   \n",
       "7579  10831  wrecked              Vancouver, Canada   \n",
       "7580  10832  wrecked                        London    \n",
       "7581  10833  wrecked                        Lincoln   \n",
       "\n",
       "                                                   text  target  \n",
       "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32    We always try to bring the heavy. #metal #RT h...       0  \n",
       "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                   Crying out for more! Set me ablaze       0  \n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  \n",
       "...                                                 ...     ...  \n",
       "7575  On the bright side I wrecked http://t.co/uEa0t...       0  \n",
       "7577  @widda16 ... He's gone. You can relax. I thoug...       0  \n",
       "7579  Three days off from work and they've pretty mu...       0  \n",
       "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "\n",
       "[5080 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.dropna(subset=['location'])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T01:06:43.147395Z",
     "start_time": "2024-04-20T01:06:43.041371Z"
    }
   },
   "outputs": [],
   "source": [
    "import preprocess.location as pl\n",
    "from geopy.geocoders import Nominatim\n",
    "from typing import Tuple,Any\n",
    "featuretest_data= train_data.copy()\n",
    "\n",
    "class ConversionProgress(pl.GeolocationStepConverter):\n",
    "    def __init__(self,frequency:int):\n",
    "        self.frequency=frequency\n",
    "        self.counter=0\n",
    "        self.progress=0\n",
    "    def convert(self, address:str)-> Tuple[Any,bool]:\n",
    "        self.progress+=1\n",
    "        self.counter+=1\n",
    "        if self.counter >= self.frequency:\n",
    "            self.counter=0\n",
    "            print(f\"Current progress: {self.progress}\")\n",
    "        return address,False    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Livingston, IL  U.S.A.',), **{'addressdetails': True}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connection.py\", line 466, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 1390, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 539, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 370, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Livingston%2C+IL++U.S.A.&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Livingston%2C+IL++U.S.A.&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Livingston%2C+IL++U.S.A.&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('In the middle of no where',), **{'addressdetails': True}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connection.py\", line 466, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 1390, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 539, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 370, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=In+the+middle+of+no+where&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=In+the+middle+of+no+where&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=In+the+middle+of+no+where&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: 100\n",
      "Current progress: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('?s????ss? a?????',), **{'addressdetails': True}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connection.py\", line 466, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 1390, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 539, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 370, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('?s????ss? a?????',), **{'addressdetails': True}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connection.py\", line 466, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 1390, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 539, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 370, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('?s????ss? a?????',), **{'addressdetails': True}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 537, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connection.py\", line 466, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 1390, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/http/client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/ssl.py\", line 1166, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 793, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 539, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 370, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 877, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 847, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/util/retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ramizouari/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=%3Fs%3F%3F%3F%3Fss%3F+a%3F%3F%3F%3F%3F&format=json&limit=1&addressdetails=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: 300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m layer\u001b[38;5;241m.\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mappend(pl\u001b[38;5;241m.\u001b[39mLatLongToGeolocation(rateLimited))\n\u001b[1;32m      7\u001b[0m layer\u001b[38;5;241m.\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mappend(pl\u001b[38;5;241m.\u001b[39mAddressToGeolocation(rateLimited))\n\u001b[0;32m----> 8\u001b[0m featuretest_data\u001b[38;5;241m=\u001b[39m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeaturetest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:238\u001b[0m, in \u001b[0;36mDefaultPreprocessLocationLayer.preprocess\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess the location\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    pd.DataFrame: The preprocessed dataframe, with the additional geolocation and geolocation_converted columns\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare(df)\n\u001b[0;32m--> 238\u001b[0m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeolocation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeolocation_converted\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/frame.py:10347\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10333\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10335\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10337\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10345\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10346\u001b[0m )\n\u001b[0;32m> 10347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:219\u001b[0m, in \u001b[0;36mDefaultPreprocessLocationLayer._task\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mgeolocation_converted:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [row\u001b[38;5;241m.\u001b[39mgeolocation,row\u001b[38;5;241m.\u001b[39mgeolocation_converted]\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:197\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(location, transformers)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m location, transformed\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:197\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(location, transformers)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m location, transformed\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:197\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(location, transformers)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m location, transformed\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:194\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(location, transformers)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(transformers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m location, transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m location, transformed\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:119\u001b[0m, in \u001b[0;36mGeolocationStepConverter.__call__\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, location :\u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/NLPCompetition1/preprocess/location.py:151\u001b[0m, in \u001b[0;36mAddressToGeolocation.convert\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m extracted:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m address, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeolocator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeocode\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddressdetails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m address, \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py:272\u001b[0m, in \u001b[0;36mRateLimiter.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retries_gen(args, kwargs)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_request_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py:267\u001b[0m, in \u001b[0;36mRateLimiter._acquire_request_slot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_request_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m wait \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_request_slot_gen():\n\u001b[0;32m--> 267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/geopy/extra/rate_limiter.py:263\u001b[0m, in \u001b[0;36mRateLimiter._sleep\u001b[0;34m(self, seconds)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sleep\u001b[39m(\u001b[38;5;28mself\u001b[39m, seconds):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sleep(\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, seconds)\n\u001b[0;32m--> 263\u001b[0m     sleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "rateLimited = pl.RateLimitedGeocoder(geoLoc, min_delay_seconds=1)\n",
    "layer=pl.DefaultPreprocessLocationLayer(force_update=False)\n",
    "layer.transformers.append(ConversionProgress(frequency=100))\n",
    "layer.transformers.append(pl.StripLocation())\n",
    "layer.transformers.append(pl.LatLongToGeolocation(rateLimited))\n",
    "layer.transformers.append(pl.AddressToGeolocation(rateLimited))\n",
    "featuretest_data=layer.preprocess(featuretest_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featuretest_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfeaturetest_data\u001b[49m\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'featuretest_data' is not defined"
     ]
    }
   ],
   "source": [
    "featuretest_data.to_pickle(\"location.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuretest_data=pd.read_pickle(\"location.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>geolocation_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "      <td>(Birmingham, West Midlands Combined Authority,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "      <td>(Africa, (11.5024338, 17.7578122))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>(Philadelphia, Philadelphia County, Pennsylvan...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "      <td>(London, Greater London, England, United Kingd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>10826</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>TN</td>\n",
       "      <td>On the bright side I wrecked http://t.co/uEa0t...</td>\n",
       "      <td>0</td>\n",
       "      <td>(تونس, (33.8439408, 9.400138))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>10829</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>#NewcastleuponTyne #UK</td>\n",
       "      <td>@widda16 ... He's gone. You can relax. I thoug...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>10831</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Three days off from work and they've pretty mu...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Vancouver, Metro Vancouver Regional District,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>10832</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>London</td>\n",
       "      <td>#FX #forex #trading Cramer: Iger's 3 words tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>(London, Greater London, England, United Kingd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Lincoln, Lancaster County, Nebraska, United S...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5080 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                       location  \\\n",
       "31       48   ablaze                     Birmingham   \n",
       "32       49   ablaze  Est. September 2012 - Bristol   \n",
       "33       50   ablaze                         AFRICA   \n",
       "34       52   ablaze               Philadelphia, PA   \n",
       "35       53   ablaze                     London, UK   \n",
       "...     ...      ...                            ...   \n",
       "7575  10826  wrecked                             TN   \n",
       "7577  10829  wrecked         #NewcastleuponTyne #UK   \n",
       "7579  10831  wrecked              Vancouver, Canada   \n",
       "7580  10832  wrecked                        London    \n",
       "7581  10833  wrecked                        Lincoln   \n",
       "\n",
       "                                                   text  target  \\\n",
       "31    @bbcmtd Wholesale Markets ablaze http://t.co/l...       1   \n",
       "32    We always try to bring the heavy. #metal #RT h...       0   \n",
       "33    #AFRICANBAZE: Breaking news:Nigeria flag set a...       1   \n",
       "34                   Crying out for more! Set me ablaze       0   \n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0   \n",
       "...                                                 ...     ...   \n",
       "7575  On the bright side I wrecked http://t.co/uEa0t...       0   \n",
       "7577  @widda16 ... He's gone. You can relax. I thoug...       0   \n",
       "7579  Three days off from work and they've pretty mu...       0   \n",
       "7580  #FX #forex #trading Cramer: Iger's 3 words tha...       0   \n",
       "7581  @engineshed Great atmosphere at the British Li...       0   \n",
       "\n",
       "                                            geolocation  geolocation_converted  \n",
       "31    (Birmingham, West Midlands Combined Authority,...                   True  \n",
       "32                                                  NaN                  False  \n",
       "33                   (Africa, (11.5024338, 17.7578122))                   True  \n",
       "34    (Philadelphia, Philadelphia County, Pennsylvan...                   True  \n",
       "35    (London, Greater London, England, United Kingd...                   True  \n",
       "...                                                 ...                    ...  \n",
       "7575                     (تونس, (33.8439408, 9.400138))                   True  \n",
       "7577                                                NaN                  False  \n",
       "7579  (Vancouver, Metro Vancouver Regional District,...                   True  \n",
       "7580  (London, Greater London, England, United Kingd...                   True  \n",
       "7581  (Lincoln, Lancaster County, Nebraska, United S...                   True  \n",
       "\n",
       "[5080 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuretest_data[\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myass\\AppData\\Local\\Temp\\ipykernel_11144\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Natural Language Processing with Disaster Tweets",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
